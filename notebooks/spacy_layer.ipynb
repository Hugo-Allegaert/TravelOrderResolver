{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174e1344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import difflib\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f18eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsorin/mambaforge/envs/ia/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'fr_core_news_sm' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d275ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_cities_df = pd.read_csv(r'city_name.csv')\n",
    "french_cities = french_cities_df.iloc[:, 0].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d378e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Je voudrais un trajet de paris vers brest.\",\n",
    "    \"Je veut arriver à nantes en partant de lyon.\",\n",
    "    \"je voudrais aller de Paris à Nantes.\",\n",
    "    \"Il me faudrait aller de Rennes à Bordeaux.\",\n",
    "    \"Je dois faire le trajet de Brest à Strasbourg.\",\n",
    "    \"Il faudrait que j'aille de Tours à Paris Gare du Nord.\",\n",
    "    \"J'aimerai faire Toulouse Nice.\",\n",
    "    \"Comment aller de Marseille à Cannes?\",\n",
    "    \"Il me faudrait un billet Angers Cahors.\",\n",
    "    \"Comment aller à Nantes en partant de Rennes?\",\n",
    "    \"Comment faire pour aller à Strasbourg depuis Toulouse?\",\n",
    "    \"Comment se procurer un billet pour partir de Nice et aller à Brest?\",\n",
    "    \"Comment voyager de Paris à Nantes?\",\n",
    "    \"Comment faire le trajet Challans Orléans?\",\n",
    "    \"Je suis à Nantes, je veux aller à Paris\",\n",
    "    \"Je suis à Bordeaux, je veux aller à Toulouse\",\n",
    "    \"Je voudrais un trajet de Brest à la Roche-sur-Yon\",\n",
    "    \"Je veux aller de Paris Gare du Nord à Nantes\",\n",
    "    \"Comment aller à Paris Gare du Nord en partant de Nantes?\",\n",
    "    \"Comment aller à Paris Gare de Lyon en partant de Nantes?\",\n",
    "    \"Comment aller à Nantes en partant de Paris Gare de Lyon?\",\n",
    "    \"Comment aller à Nantes en partant de Paris Gare du Nord?\",\n",
    "    \"j'aimerai faire un trajet Paris-Montparnasse vers Nantes\",\n",
    "    \"j'aimerai faire un trajet Nantes vers Paris-Montparnasse\",\n",
    "    \"Aller de Brest à Nantes\",\n",
    "    \"En partant de Brest je veux aller à Nantes.\",\n",
    "    \"Je veux aller à Paris\",\n",
    "    \"Je veux aller de Nantes au Havre\",\n",
    "    \"J'aimerai aller à Paris Gare Montparnasse en partant de Nantes\",\n",
    "    \"Je veux aller de Paris Gare MontParnasse à Nantes\",\n",
    "    \"Je veux aller de Nantes à Paris Gare de Lyon\",\n",
    "    \"Je veux aller de Paris Gare du Nord à Nantes\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f87ced60",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_csv(r'augmented_data.csv')\n",
    "#texts = texts_df.iloc[:, 0].str.lower()\n",
    "validity_list = texts_df.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0013afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_words = [\"aller\", \"voyage\", \"destination\", \"emmener\", \"vers\", \"arriver\", \"partir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26c6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_origin_words = [\"de\", \"depuis\", \"du\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a1ad85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_destination_words= [\"à\", \"a\", \"au\", \"vers\", \"-\", \"jusque\", \"jusqu'à\", \"jusqu'a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e920c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_words = prefix_origin_words + prefix_destination_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b3f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_prefix_words = [\"le\", \"la\", \"du\", \"de\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7b11c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_texts = 0\n",
    "total_valid_texts = 0\n",
    "total_invalid_texts = 0\n",
    "total_valid_texts_with_cities_found = 0\n",
    "total_valid_texts_with_cities_not_found = 0\n",
    "total_invalid_texts_with_cities_found = 0\n",
    "total_invalid_texts_with_cities_not_found = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa800c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_texts_with_cities_not_found = []\n",
    "invalid_texts_with_cities_found = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc86d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str):\n",
    "    text = text.strip(\".\")\n",
    "    text = text.replace(\",\", \"\")\n",
    "    text = text.strip(\"?\")\n",
    "    #text = text.replace(\"'\", \" \")\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8995ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text: str):\n",
    "    text = clean_text(text)\n",
    "    return text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ceeb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_before(text: str, first_words: List[str], second_word: str):\n",
    "        \n",
    "    text_split = split_text(text)\n",
    "    \n",
    "    list_result = []\n",
    "    \n",
    "    for first_word in first_words:\n",
    "        \n",
    "        if first_word not in text_split or (second_word not in text_split and second_word not in text):\n",
    "            list_result.append(False)\n",
    "        else:    \n",
    "\n",
    "            first_result = False\n",
    "            second_result = False\n",
    "            third_result = False\n",
    "\n",
    "            first_word_index = text_split.index(first_word)\n",
    "\n",
    "            if second_word in text_split: \n",
    "\n",
    "                second_word_index = text_split.index(second_word)\n",
    "\n",
    "                if text_split.count(first_word) > 1 and text_split[second_word_index - 1] == first_word:\n",
    "                    first_word_index = second_word_index - 1\n",
    "\n",
    "                first_result = second_word_index - first_word_index == 1\n",
    "\n",
    "                if not first_result:\n",
    "                    prefix = text_split[second_word_index - 1]\n",
    "\n",
    "                    if prefix == \"la\" or prefix == \"le\" or prefix == \"l'\":\n",
    "                        prefix_index = text_split.index(prefix)\n",
    "                        second_result = prefix_index - first_word_index == 1          \n",
    "\n",
    "            if (not first_result or not second_result) and (second_word not in text_split and second_word in text):\n",
    "                second_word_split = []\n",
    "\n",
    "                if len(second_word.split(\" \")) > 1:\n",
    "                    second_word_split = second_word.split(\" \")\n",
    "                if len(second_word.split(\"-\")) > 1:\n",
    "                    second_word_split = second_word.split(\"-\")   \n",
    "\n",
    "                if second_word_split and second_word_split[0] in text_split:\n",
    "                    second_word_first_word_index = text_split.index(second_word_split[0])\n",
    "                    third_result = second_word_first_word_index - first_word_index == 1 \n",
    "\n",
    "            list_result.append(first_result or second_result or third_result)\n",
    "\n",
    "    return any(result for result in list_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d975068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_city(city: str):\n",
    "    city = city.replace(\"la \", \"\")\n",
    "    city = city.replace(\"le \", \"\")\n",
    "    city = city.replace(\"l' \", \"\")\n",
    "    return city.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a362c4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je voudrais un trajet de paris vers brest.\n",
      "ORIGIN :  ['paris-st-lazare', 'paris gare du nord', 'paris-bercy', 'paris-montparnasse 1-2', 'paris-austerlitz', 'paris-est', 'paris-gare-de-lyon', 'paris-montp.3-vaug.']\n",
      "DESTINATION :  ['brest']\n",
      "------\n",
      "Je veut arriver à nantes en partant de lyon.\n",
      "ORIGIN :  ['lyon-jean-macé']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "je voudrais aller de Paris à Nantes.\n",
      "ORIGIN :  ['paris-st-lazare', 'paris gare du nord', 'paris-bercy', 'paris-montparnasse 1-2', 'paris-austerlitz', 'paris-est', 'paris-gare-de-lyon', 'paris-montp.3-vaug.']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "Il me faudrait aller de Rennes à Bordeaux.\n",
      "ORIGIN :  ['rennes']\n",
      "DESTINATION :  ['bordeaux-st-jean']\n",
      "------\n",
      "Je dois faire le trajet de Brest à Strasbourg.\n",
      "ORIGIN :  ['brest']\n",
      "DESTINATION :  ['strasbourg', 'strasbourg-roethig']\n",
      "------\n",
      "Il faudrait que j'aille de Tours à Paris Gare du Nord.\n",
      "ORIGIN :  ['tours']\n",
      "DESTINATION :  ['paris gare du nord']\n",
      "------\n",
      "J'aimerai faire Toulouse Nice.\n",
      "ORIGIN :  ['toulouse-matabiau']\n",
      "DESTINATION :  ['nice-pont-michel', 'nice-riquier', 'nice-st-augustin', 'nice-ville']\n",
      "------\n",
      "Comment aller de Marseille à Cannes?\n",
      "ORIGIN :  ['marseille-blancarde', 'marseille-en-beauvaisis', 'marseille-st-charles']\n",
      "DESTINATION :  ['cannes']\n",
      "------\n",
      "Il me faudrait un billet Angers Cahors.\n",
      "ORIGIN :  ['angers-st-laud', 'angers-maitre-ecole']\n",
      "DESTINATION :  ['cahors']\n",
      "------\n",
      "Comment aller à Nantes en partant de Rennes?\n",
      "ORIGIN :  ['rennes']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "Comment faire pour aller à Strasbourg depuis Toulouse?\n",
      "ORIGIN :  ['toulouse-matabiau']\n",
      "DESTINATION :  ['strasbourg', 'strasbourg-roethig']\n",
      "------\n",
      "Comment se procurer un billet pour partir de Nice et aller à Brest?\n",
      "ORIGIN :  ['nice-pont-michel', 'nice-riquier', 'nice-st-augustin', 'nice-ville']\n",
      "DESTINATION :  ['brest']\n",
      "------\n",
      "Comment voyager de Paris à Nantes?\n",
      "ORIGIN :  ['paris-st-lazare', 'paris gare du nord', 'paris-bercy', 'paris-montparnasse 1-2', 'paris-austerlitz', 'paris-est', 'paris-gare-de-lyon', 'paris-montp.3-vaug.']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "Comment faire le trajet Challans Orléans?\n",
      "ORIGIN :  ['challans']\n",
      "DESTINATION :  ['orléans']\n",
      "------\n",
      "Je suis à Nantes, je veux aller à Paris\n",
      "ORIGIN :  ['nantes']\n",
      "DESTINATION :  ['paris-st-lazare', 'paris gare du nord', 'paris-bercy', 'paris-montparnasse 1-2', 'paris-austerlitz', 'paris-est', 'paris-gare-de-lyon', 'paris-montp.3-vaug.']\n",
      "------\n",
      "Je suis à Bordeaux, je veux aller à Toulouse\n",
      "ORIGIN :  ['bordeaux-st-jean']\n",
      "DESTINATION :  ['toulouse-matabiau']\n",
      "------\n",
      "Je voudrais un trajet de Brest à la Roche-sur-Yon\n",
      "ORIGIN :  ['brest']\n",
      "DESTINATION :  ['la roche-sur-yon']\n",
      "------\n",
      "Je veux aller de Paris Gare du Nord à Nantes\n",
      "ORIGIN :  ['paris gare du nord']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "Comment aller à Paris Gare du Nord en partant de Nantes?\n",
      "ORIGIN :  ['nantes']\n",
      "DESTINATION :  ['paris gare du nord']\n",
      "------\n",
      "Comment aller à Paris Gare de Lyon en partant de Nantes?\n",
      "ORIGIN :  ['nantes']\n",
      "DESTINATION :  ['paris-gare-de-lyon']\n",
      "------\n",
      "Comment aller à Nantes en partant de Paris Gare de Lyon?\n",
      "ORIGIN :  ['paris-gare-de-lyon']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "Comment aller à Nantes en partant de Paris Gare du Nord?\n",
      "ORIGIN :  ['paris gare du nord']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "j'aimerai faire un trajet Paris-Montparnasse vers Nantes\n",
      "ORIGIN :  ['paris-montparnasse 1-2']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "j'aimerai faire un trajet Nantes vers Paris-Montparnasse\n",
      "ORIGIN :  ['nantes']\n",
      "DESTINATION :  ['paris-montparnasse 1-2']\n",
      "------\n",
      "Aller de Brest à Nantes\n",
      "ORIGIN :  ['brest']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "En partant de Brest je veux aller à Nantes.\n",
      "ORIGIN :  ['brest']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "Je veux aller à Paris\n",
      "ORIGIN :  []\n",
      "DESTINATION :  []\n",
      "------\n",
      "Je veux aller de Nantes au Havre\n",
      "ORIGIN :  ['nantes']\n",
      "DESTINATION :  ['le havre', 'le havre-graville']\n",
      "------\n",
      "J'aimerai aller à Paris Gare Montparnasse en partant de Nantes\n",
      "ORIGIN :  ['nantes']\n",
      "DESTINATION :  ['paris-montparnasse 1-2']\n",
      "------\n",
      "Je veux aller de Paris Gare MontParnasse à Nantes\n",
      "ORIGIN :  ['paris-montparnasse 1-2']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n",
      "Je veux aller de Nantes à Paris Gare de Lyon\n",
      "ORIGIN :  ['nantes']\n",
      "DESTINATION :  ['paris-gare-de-lyon']\n",
      "------\n",
      "Je veux aller de Paris Gare du Nord à Nantes\n",
      "ORIGIN :  ['paris gare du nord']\n",
      "DESTINATION :  ['nantes']\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for text_index, text in enumerate(texts):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    text_cities = []\n",
    "    text_travel_words = []\n",
    "    locations = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.text.lower() not in wrong_prefix_words:    \n",
    "            locations.append(clean_text(ent.text.lower()))\n",
    "        text_cities.extend([french_city for french_city in french_cities if french_city.startswith(clean_text(ent.text)) \n",
    "                                                                         or clean_text(ent.text) in french_city \n",
    "                                                                         or french_city.startswith(clean_text(ent.text).replace(\" \", \"-\"))\n",
    "                                                                         or clean_text(ent.text).replace(\" \", \"-\") in french_city])\n",
    "        if len(ent.text.split(\" \")) > 1 and not text_cities:\n",
    "            for word in ent.text.split(\" \"):\n",
    "                text_cities.extend([french_city for french_city in french_cities if french_city.startswith(clean_text(word)) \n",
    "                                                                                 or clean_text(word) in french_city\n",
    "                                                                                 or french_city.startswith(clean_text(word).replace(\" \", \"-\"))\n",
    "                                                                                 or clean_text(word).replace(\" \", \"-\") in french_city]) \n",
    "            \n",
    "    for token in doc:\n",
    "        if any(token.lemma_ == travel_word for travel_word in travel_words):\n",
    "            text_travel_words.append(token.text)\n",
    "    \n",
    "    text_split = split_text(text)\n",
    "    \n",
    "    loca = locations\n",
    "    \n",
    "    if len(locations) <= 1:\n",
    "        if len(list(set(text_split).intersection(prefix_origin_words))) > 0 and len(list(set(text_split).intersection(prefix_destination_words))) > 0:\n",
    "            for index, word in enumerate(text_split):\n",
    "                if word in prefix_words:\n",
    "                    if len(text_split) > index + 1:\n",
    "                        if text_split[index + 1] in wrong_prefix_words and len(text_split) > index + 2:\n",
    "                            locations.append(text_split[index + 2])\n",
    "                        else:\n",
    "                            locations.append(text_split[index + 1])\n",
    "            for location in locations:\n",
    "                text_cities.extend([french_city for french_city in french_cities if french_city.startswith(clean_text(location)) or clean_text(location) in french_city])\n",
    "    if len(locations) <= 1:\n",
    "        temp_text = text[0].lower() + text[1:]\n",
    "        temp_text_split = temp_text.split(\" \")\n",
    "        for tts in temp_text_split:\n",
    "            if tts[0] == tts[0].upper() and clean_text(tts) not in locations:\n",
    "                locations.append(clean_text(tts))\n",
    "                text_cities.extend([french_city for french_city in french_cities if french_city.startswith(clean_text(tts)) or clean_text(tts) in french_city]) \n",
    "        if len(locations) == 2 and is_before(clean_text(text), [locations[1]], locations[0]):\n",
    "            locations.reverse()        \n",
    "    \n",
    "    locations = list(dict.fromkeys(locations))\n",
    "    text_cities = list(dict.fromkeys(text_cities))\n",
    "    text_travel_words = list(dict.fromkeys(text_travel_words))\n",
    "    \n",
    "    origins = []\n",
    "    destinations = []\n",
    "    \n",
    "    for location in locations:\n",
    "        \n",
    "        if len(list(set(text_split).intersection(prefix_origin_words))) > 0 and len(list(set(text_split).intersection(prefix_destination_words))) > 0: \n",
    "            #print(\"1\")\n",
    "            if is_before(clean_text(text), prefix_origin_words, clean_city(location)):\n",
    "                #print(\"1.1\")\n",
    "                origins.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(location) or clean_city(text_city).startswith(location.replace(\" \", \"-\"))])\n",
    "            if is_before(clean_text(text), prefix_destination_words, clean_city(location)):\n",
    "                #print(\"1.2\")\n",
    "                destinations.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(location) or clean_city(text_city).startswith(location.replace(\" \", \"-\"))])\n",
    "    \n",
    "    if not origins and not destinations and len(locations[0].split(\" \")) > 1:\n",
    "        #print(\"2\")\n",
    "        if is_before(clean_text(text), [clean_city(locations[0].split(\" \")[0])], clean_city(locations[0].split(\" \")[1])):\n",
    "            origins.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(locations[0].split(\" \")[0])])\n",
    "            destinations.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(locations[0].split(\" \")[1])])   \n",
    "\n",
    "    if not origins and not destinations and len(locations) == 2:\n",
    "        #print(\"3\")\n",
    "        if (len(list(set(text_split).intersection(prefix_origin_words))) > 0 or len(list(set(text_split).intersection(prefix_destination_words))) > 0) and text_split.count(\"à\") < 2 and text_split.count(\"a\") < 2:\n",
    "            for location in locations:\n",
    "                if is_before(clean_text(text), prefix_origin_words, clean_city(location)):\n",
    "                    #print(\"3.1.1\")\n",
    "                    origins.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(location) or clean_city(text_city).startswith(location.replace(\" \", \"-\"))])\n",
    "                if is_before(clean_text(text), prefix_destination_words, clean_city(location)):\n",
    "                    #print(\"3.1.2\")\n",
    "                    destinations.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(location) or clean_city(text_city).startswith(location.replace(\" \", \"-\"))])\n",
    "        else:   \n",
    "            #print(\"3.2\")\n",
    "            for travel_word in text_travel_words:\n",
    "                city = locations[0]\n",
    "                if len(locations[0].split(\" \")) > 1:\n",
    "                    city = locations[0].split(\" \")[0]\n",
    "                if travel_word in text_split and clean_city(city) in text_split and (text_split.index(travel_word) > text_split.index(clean_city(city))):\n",
    "                    origins.extend([text_city for text_city in text_cities if text_city.startswith(locations[0]) or text_city.startswith(locations[0].replace(\" \", \"-\"))])\n",
    "                    destinations.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(locations[1]) or clean_city(text_city).startswith(locations[1].replace(\" \", \"-\"))])\n",
    "                else:\n",
    "                    origins.extend([text_city for text_city in text_cities if text_city.startswith(locations[1]) or text_city.startswith(locations[1].replace(\" \", \"-\"))])\n",
    "                    destinations.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(locations[0]) or clean_city(text_city).startswith(locations[0].replace(\" \", \"-\"))])       \n",
    "    \n",
    "    if not origins and not destinations and len(locations) == 2:\n",
    "        #print(\"4\")\n",
    "        origins.extend([text_city for text_city in text_cities if text_city.startswith(locations[0]) or text_city.startswith(locations[0].replace(\" \", \"-\"))])\n",
    "        destinations.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(locations[1]) or clean_city(text_city).startswith(locations[1].replace(\" \", \"-\"))])\n",
    "    \n",
    "    if len(locations) == 2:\n",
    "        if locations[0] in origins:\n",
    "            origins = difflib.get_close_matches(locations[0], origins)\n",
    "        if locations[0] in destinations:\n",
    "            destinations = difflib.get_close_matches(locations[0], destinations)\n",
    "        if locations[1] in origins:\n",
    "            origins = difflib.get_close_matches(locations[1], origins)\n",
    "        if locations[1] in destinations:\n",
    "            destinations = difflib.get_close_matches(locations[1], destinations)        \n",
    "            \n",
    "    if not origins and destinations:\n",
    "        #print(\"5\")\n",
    "        for location in locations:\n",
    "            if len(difflib.get_close_matches(location, destinations)) == 0:\n",
    "                origins.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(location) or clean_city(text_city).startswith(location.replace(\" \", \"-\"))])\n",
    "        if not origins:\n",
    "            for location in locations:\n",
    "                if len(difflib.get_close_matches(location, destinations)) == 0 and len(location.split(\" \")) > 1:\n",
    "                    for loc_split in location.split(\" \"):\n",
    "                        if loc_split not in prefix_words:\n",
    "                            origins.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(loc_split) or clean_city(text_city).startswith(loc_split.replace(\" \", \"-\"))])                    \n",
    "    if origins and not destinations:\n",
    "        #print(\"6\")\n",
    "        for location in locations:\n",
    "            if len(difflib.get_close_matches(location, origins)) == 0:\n",
    "                destinations.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(location) or clean_city(text_city).startswith(location.replace(\" \", \"-\"))])\n",
    "        if not destinations:\n",
    "            for location in locations:\n",
    "                if len(difflib.get_close_matches(location, origins)) == 0 and len(location.split(\" \")) > 1:\n",
    "                    for loc_split in location.split(\" \"):\n",
    "                        if loc_split not in prefix_words:\n",
    "                            destinations.extend([text_city for text_city in text_cities if clean_city(text_city).startswith(loc_split) or clean_city(text_city).startswith(loc_split.replace(\" \", \"-\"))])       \n",
    "    if len(origins) > 1:\n",
    "        #print(\"7\", origins)\n",
    "        temp_origins = []\n",
    "        for t in text_split:\n",
    "            if t not in wrong_prefix_words and t.lower() != \"gare\" and any(t.lower() in o for o in origins):\n",
    "                if not temp_origins:\n",
    "                    temp_origins.extend([origin for origin in origins if t.lower() in origin])\n",
    "                else:\n",
    "                    temp_origins = list(set(temp_origins).intersection([origin for origin in origins if t.lower() in origin]))\n",
    "        origins = temp_origins    \n",
    "    if len(destinations) > 1:\n",
    "        #print(\"8\", destinations)\n",
    "        temp_destinations = []\n",
    "        for t in text_split:\n",
    "            if t not in wrong_prefix_words and t.lower() != \"gare\" and any(t.lower() in d for d in destinations):\n",
    "                if not temp_destinations:\n",
    "                    temp_destinations.extend([destination for destination in destinations if t.lower() in destination])\n",
    "                else:\n",
    "                    temp_destinations = list(set(temp_destinations).intersection([destination for destination in destinations if t.lower() in destination]))\n",
    "        destinations = temp_destinations            \n",
    "    \n",
    "    print(text)\n",
    "    #print(\"LOCA\", loca)\n",
    "    #print(\"locations\", locations)\n",
    "    #print(\"TEXT CITIES\", text_cities)\n",
    "    #print(\"TEXT TRAVEL WORDS\", text_travel_words)\n",
    "    print(\"ORIGIN : \", list(dict.fromkeys(origins)))\n",
    "    print(\"DESTINATION : \", list(dict.fromkeys(destinations)))\n",
    "    print(\"------\")  \n",
    "    \n",
    "    #text_validity = validity_list[text_index]\n",
    "    \n",
    "    #total_texts +=1\n",
    "    \n",
    "    #if text_validity == 1:   \n",
    "        #total_valid_texts += 1\n",
    "        #if origins and destinations:\n",
    "            #total_valid_texts_with_cities_found += 1\n",
    "        #else:\n",
    "            #total_valid_texts_with_cities_not_found += 1\n",
    "            #valid_texts_with_cities_not_found.append(text)\n",
    "            \n",
    "            #print(text)\n",
    "            #print(\"LOCA\", loca)\n",
    "            #print(\"locations\", locations)\n",
    "            #print(\"TEXT CITIES\", text_cities)\n",
    "            #print(\"TEXT TRAVEL WORDS\", text_travel_words)\n",
    "            #print(\"ORIGIN : \", list(dict.fromkeys(origins)))\n",
    "            #print(\"DESTINATION : \", list(dict.fromkeys(destinations)))\n",
    "            #print(\"------\")   \n",
    "        \n",
    "    #else:\n",
    "        #total_invalid_texts +=1\n",
    "        #if origins and destinations:\n",
    "            #total_invalid_texts_with_cities_found += 1\n",
    "            #invalid_texts_with_cities_found.append(text)\n",
    "        #else:\n",
    "             #total_invalid_texts_with_cities_not_found += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf8bc3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"TOTAL TEXTS\", total_texts)\n",
    "#print(\"TOTAL VALID TEXTS\", total_valid_texts)\n",
    "#print(\"TOTAL VALID TEXTS WITH CITIES FOUND\", total_valid_texts_with_cities_found)\n",
    "#print(\"TOTAL VALID TEXTS WITH CITIES NOT FOUND\", total_valid_texts_with_cities_not_found)\n",
    "#print(\"TOTAL INVALID TEXTS\", total_invalid_texts)\n",
    "#print(\"TOTAL INVALID TEXTS WITH CITIES FOUND\", total_invalid_texts_with_cities_found)\n",
    "#print(\"TOTAL INVALID TEXTS WITH CITIES NOT FOUND\", total_invalid_texts_with_cities_not_found)\n",
    "\n",
    "#print(\"good text success percentage\", (total_valid_texts_with_cities_found / total_valid_texts) * 100)#\n",
    "#print(\"bad text success percentage\", (total_invalid_texts_with_cities_not_found / total_invalid_texts) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c81015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_texts_with_cities_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aeb96f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_texts_with_cities_found"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
